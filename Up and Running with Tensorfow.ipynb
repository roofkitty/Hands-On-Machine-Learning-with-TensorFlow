{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic principle of TensorFlow is simple: you first define in Python a graph of computations to perform (for example, the one in Figure 9-1), and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.\n",
    "\n",
    "<figure><img src='figure9-1.png'><figcaption>Figure 9-1</figcaption></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph and run it in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Result is 42\n",
      "The Result is 42\n",
      "The Result is 42\n"
     ]
    }
   ],
   "source": [
    "# Construction phase: Setup the graph\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "# Execution phase:\n",
    "# Create a session, initialize the variable, evaluate and close the session\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print('The Result is %d' %result)\n",
    "sess.close()\n",
    "\n",
    "# A better way is to write in block to make it cleaner\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print('The Result is %d' %result)\n",
    "\n",
    "# We can also use init code to initialize all variable at once:\n",
    "init = tf.global_variables_initializer()  # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run()  # actually initialize all the variables\n",
    "    result = f.eval()\n",
    "print('The Result is %d' %result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Graphs\n",
    "Any node you create is automatically added to the default graph. But if you wan to manage multiple independent graphs, we can create new graph add node inside a with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is x1 in default graph? True\n",
      "Is x2 in default graph? False\n",
      "Is x2 in graph? True\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "print('Is x1 in default graph? %s' %str(x1.graph is tf.get_default_graph()))\n",
    "\n",
    "graph = tf.Graph() # create a graph\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "print('Is x2 in default graph? %s' %str(x2.graph is tf.get_default_graph()))\n",
    "print('Is x2 in graph? %s' %str(x2.graph is graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reset default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is x1 in default graph? False\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "tf.reset_default_graph() # remove all the nodes\n",
    "print('Is x1 in default graph? %s' %str(x1.graph is tf.get_default_graph()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a Node Value\n",
    "When evaluating a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first. It **_will_** not reuse the result of the previous evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(1)\n",
    "x = w + 1\n",
    "y = x + 1\n",
    "z = x * 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code, w and x are evaluated twice. If we want to be more efficient, we can evaluate them in one graph run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_eval, z_eval = sess.run([y, z])\n",
    "    print(y_eval)\n",
    "    print(z_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TensorFlow\n",
    "TensorFlow operations can take any number of inputs and produce any number of outputs. The inputs and ouputs are multidimensional arrays, called *tensor*. Tensors have a type and a shape. In Python API tensors are simply represented by NumPy ndarrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /Users/chengxi/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "* TensorFlow provides a number of optimizers out of the box, including a Gradient Descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  1.3835073\n",
      "Epoch  100 MSE =  1.3274424\n",
      "Epoch  200 MSE =  1.279127\n",
      "Epoch  300 MSE =  1.2346176\n",
      "Epoch  400 MSE =  1.1934859\n",
      "Epoch  500 MSE =  1.1553848\n",
      "Epoch  600 MSE =  1.1200206\n",
      "Epoch  700 MSE =  1.0871432\n",
      "Epoch  800 MSE =  1.0565367\n",
      "Epoch  900 MSE =  1.028013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "scaler = MinMaxScaler()\n",
    "scalre_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scalre_housing_data]\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch ', epoch, 'MSE = ', mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can feed data to evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[6. 7. 8.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[1,2,3],[2,3,4]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  0.9356201\n",
      "Epoch  100 MSE =  0.1406384\n",
      "Epoch  200 MSE =  0.12077526\n",
      "Epoch  300 MSE =  0.11835499\n",
      "Epoch  400 MSE =  0.11879311\n",
      "Epoch  500 MSE =  0.11948355\n",
      "Epoch  600 MSE =  0.1200376\n",
      "Epoch  700 MSE =  0.120447256\n",
      "Epoch  800 MSE =  0.12075247\n",
      "Epoch  900 MSE =  0.12098324\n"
     ]
    }
   ],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    \n",
    "    batch_start = batch_index*batch_size\n",
    "    batch_end = batch_start + batch_size\n",
    "    X_batch = scaled_housing_data_plus_bias[batch_start:batch_end, :]\n",
    "    y_batch = housing.target.reshape(-1, 1)[batch_start:batch_end, :]\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch ', epoch, 'MSE = ', mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "            \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore models\n",
    "Once we have the model, we should save its parameters to disk so we can come back and use it. Moreover, we may want to save checkpoints at regular intervals during training in case computer crashes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  1.1665298\n"
     ]
    }
   ],
   "source": [
    "# Code from examples above\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch ', epoch, 'MSE = ', mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "            save_path = saver.save(sess, 'tmp/model.ckpt')\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, 'tmp/model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/model_final.ckpt\n",
      "Epoch  0 MSE =  0.13864568\n"
     ]
    }
   ],
   "source": [
    "# Restore a saved model\n",
    "saver = tf.train.Saver() # create a Saver at construction phase\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'tmp/model_final.ckpt') # instead of init node, call restore() method of the Saver object\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        if epoch %100 == 0:\n",
    "            print('Epoch ', epoch, 'MSE = ', mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "\n",
    "n_epoches = 100\n",
    "n_batches = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='prediction')\n",
    "error = y - y_pred\n",
    "mse = tf.reduce_mean(tf.square(error), name='MSE')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "## create a node in graph that will evaluate MSE and write\n",
    "## it to TensorBloar-compatible log string called summary\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "## write summaries to logfiles in log directory\n",
    "## it will create directory if not exist\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "                \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()       \n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After create the logs, we can see it from TensorBoard server. Inside terminal for mac of command on windows:\n",
    "``` \n",
    "tensorboard --logdir tf_logs/\n",
    "```\n",
    "You will see \n",
    "``` \n",
    "TensorBoard 1.6.0 at http:/0.0.0.0:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "<figure><img src='figure9-2.png'><figcaption>Figure 9-2</figcaption></figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
